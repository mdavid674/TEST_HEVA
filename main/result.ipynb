{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical test results for HEVA company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook repeats the statement of the test. Under each activity you will find the code and the result produced.\n",
    "You will find all the requirements to run this notebook in the requirements.md file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col, when, explode, split,\\\n",
    "    desc, from_unixtime, year\n",
    "from pyspark.sql.types import DateType\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of necessary parameters\n",
    "data_path = \"../sources/data/movies.sqlite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/21 17:54:37 WARN Utils: Your hostname, cornichon resolves to a loopback address: 127.0.1.1; using 192.168.1.156 instead (on interface wlp3s0)\n",
      "22/07/21 17:54:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/matteo/anaconda3/envs/test_heva/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/matteo/.ivy2/cache\n",
      "The jars for the packages stored in: /home/matteo/.ivy2/jars\n",
      "org.xerial#sqlite-jdbc added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d1cc521a-27f9-416c-bb07-82e3cc90c4a1;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.xerial#sqlite-jdbc;3.34.0 in central\n",
      ":: resolution report :: resolve 301ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\torg.xerial#sqlite-jdbc;3.34.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d1cc521a-27f9-416c-bb07-82e3cc90c4a1\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/7ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/21 17:54:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "def read_data(data_path):\n",
    "    \"\"\" Configuring the Pyspark session with the jdbc package\n",
    "        to read the \"movies.sqlite\" file.\n",
    "\n",
    "    Args:\n",
    "        data_path (string): The sqlite data file path\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of 2 Pyspark Dataframes\n",
    "    \"\"\"\n",
    "\n",
    "    # Creation of the Spark session\n",
    "    spark = SparkSession.builder\\\n",
    "        .config(\n",
    "            'spark.jars.packages',\n",
    "            'org.xerial:sqlite-jdbc:3.34.0')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Reading the movies table\n",
    "    df_movies = spark.read.format('jdbc')\\\n",
    "        .options(\n",
    "            driver='org.sqlite.JDBC',\n",
    "            dbtable='movies',\n",
    "            url=f'jdbc:sqlite:{data_path}')\\\n",
    "        .load()\n",
    "\n",
    "    # Reading the ratings table\n",
    "    df_ratings = spark.read.format('jdbc')\\\n",
    "        .options(\n",
    "            driver='org.sqlite.JDBC',\n",
    "            dbtable='ratings',\n",
    "            url=f'jdbc:sqlite:{data_path}')\\\n",
    "        .load()\n",
    "\n",
    "    return df_movies, df_ratings\n",
    "\n",
    "\n",
    "df_movies, df_ratings = read_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|               title|               genre|\n",
      "+--------+--------------------+--------------------+\n",
      "|       8|Edison Kinetoscop...|   Documentary|Short|\n",
      "|      10|La sortie des usi...|   Documentary|Short|\n",
      "|      12|The Arrival of a ...|   Documentary|Short|\n",
      "|      25|The Oxford and Ca...|                null|\n",
      "|      91|Le manoir du diab...|        Short|Horror|\n",
      "|     131|Une nuit terrible...| Short|Comedy|Horror|\n",
      "|     417|A Trip to the Moo...|Short|Action|Adve...|\n",
      "|     439|The Great Train R...|Short|Action|Crim...|\n",
      "|     443|Hiawatha, the Mes...|                null|\n",
      "|     628|The Adventures of...|        Action|Short|\n",
      "|     833|The Country Docto...|         Short|Drama|\n",
      "|    1223| Frankenstein (1910)| Short|Horror|Sci-Fi|\n",
      "|    1740|The Lonedale Oper...| Short|Drama|Romance|\n",
      "|    2101|    Cleopatra (1912)|       Drama|History|\n",
      "|    2130|    L'inferno (1911)|Adventure|Drama|F...|\n",
      "|    2354|Max et Jane veule...|Short|Comedy|Romance|\n",
      "|    2844|Fantômas - À l'om...|         Crime|Drama|\n",
      "|    3740|      Cabiria (1914)|Adventure|Drama|H...|\n",
      "|    3863|Dough and Dynamit...|        Comedy|Short|\n",
      "|    4099|His Majesty, the ...|Family|Fantasy|Ad...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Ratings table\n",
      "+-------+--------+------+----------------+\n",
      "|user_id|movie_id|rating|rating_timestamp|\n",
      "+-------+--------+------+----------------+\n",
      "|      1|  114508|     8|      1381006850|\n",
      "|      2|  499549|     9|      1376753198|\n",
      "|      2| 1305591|     8|      1376742507|\n",
      "|      2| 1428538|     1|      1371307089|\n",
      "|      3|   75314|     1|      1595468524|\n",
      "|      3|  102926|     9|      1590148016|\n",
      "|      3|  114369|    10|      1597555347|\n",
      "|      3|  118715|     8|      1596006798|\n",
      "|      3|  120737|     8|      1599306720|\n",
      "|      3|  208092|     5|      1586466072|\n",
      "|      3|  358273|     9|      1579057827|\n",
      "|      3|  477348|     6|      1597289003|\n",
      "|      3|10039344|     5|      1578603053|\n",
      "|      3| 1051906|     6|      1589924916|\n",
      "|      3| 1568346|     6|      1597388722|\n",
      "|      3| 2278388|     8|      1597297732|\n",
      "|      3| 6199572|     3|      1589482483|\n",
      "|      3| 6723592|     8|      1599578941|\n",
      "|      3| 6751668|     9|      1578955697|\n",
      "|      3| 7131622|     8|      1579559244|\n",
      "+-------+--------+------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preview_data(df_movies, df_ratings):\n",
    "    \"\"\"Showing top 20 rows\n",
    "\n",
    "    Args:\n",
    "        df_movies (Dataframe): Movies Dataframe\n",
    "        df_ratings (Dataframe): Ratings Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Overview of movies table data\n",
    "    print(\"Movies table\")\n",
    "    df_movies.show()\n",
    "\n",
    "    # Preview data from the ratings table\n",
    "    print(\"Ratings table\")\n",
    "    df_ratings.show()\n",
    "\n",
    "\n",
    "preview_data(df_movies, df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "### 1. Counts\n",
    "\n",
    "- 1.1 How many films are in the database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37947 movies in the database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def activity_1_1(df_movies):\n",
    "    \"\"\"Counting the number of distinct film titles\n",
    "\n",
    "    Args:\n",
    "        df_movies (Dataframe): Movies Dataframe\n",
    "\n",
    "    Return:\n",
    "        int: Number of movies\n",
    "    \"\"\"\n",
    "\n",
    "    return df_movies\\\n",
    "        .select(\"title\")\\\n",
    "        .distinct()\\\n",
    "        .count()\n",
    "\n",
    "\n",
    "result_1_1 = activity_1_1(df_movies)\n",
    "print(\"There are\", result_1_1, \"movies in the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1.2 How many different users are in the database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 71707 user id in the database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def activity_1_2(df_ratings):\n",
    "    \"\"\"Counting the number of distinct user id\n",
    "\n",
    "    Args:\n",
    "        df_ratings (Dataframe): Ratings Dataframe\n",
    "\n",
    "    Return:\n",
    "        int: Number of user id\n",
    "    \"\"\"\n",
    "\n",
    "    return df_ratings\\\n",
    "        .select(\"user_id\")\\\n",
    "        .distinct()\\\n",
    "        .count()\n",
    "\n",
    "\n",
    "result_1_2 = activity_1_2(df_ratings)\n",
    "print(\"There are\", result_1_2, \"user id in the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1.3 What is the distribution of the notes provided?\n",
    "     **Bonus**: create a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Dataframe to Pandas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings distribution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|rating| count|\n",
      "+------+------+\n",
      "|     0|   281|\n",
      "|     1| 10814|\n",
      "|     2|  9223|\n",
      "|     3| 15487|\n",
      "|     4| 28193|\n",
      "|     5| 69747|\n",
      "|     6|120370|\n",
      "|     7|206680|\n",
      "|     8|222146|\n",
      "|     9|130106|\n",
      "|    10|108351|\n",
      "+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def activity_1_3(df_ratings):\n",
    "    \"\"\" Display rating distribution histogramme\n",
    "        Counting the number of voters per rating\n",
    "        Sorting based on ratings\n",
    "\n",
    "    Args:\n",
    "        df_ratings (Dataframe): Ratings Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Creation of the histogram\n",
    "    print(\"Converting Dataframe to Pandas...\")\n",
    "    plt.hist(\n",
    "        df_ratings.select(\"rating\").toPandas().squeeze(),\n",
    "        bins=11)  # [0 to 10] => 11 values\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Number of rating')\n",
    "    plt.title('Histogram of rating')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Ratings distribution\")\n",
    "    df_ratings\\\n",
    "        .groupBy(\"rating\")\\\n",
    "        .count()\\\n",
    "        .orderBy(\"rating\")\\\n",
    "        .show()\n",
    "\n",
    "\n",
    "activity_1_3(df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1.4 Finally, we want to obtain a table of frequencies to express the distribution of notes as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings frequencies\n",
      "+------+-------------------+\n",
      "|rating|         percentage|\n",
      "+------+-------------------+\n",
      "|     0|0.03049713587396543|\n",
      "|     1| 1.1736513428507551|\n",
      "|     2| 1.0009789472084811|\n",
      "|     3| 1.6808154565128208|\n",
      "|     4| 3.0598069455327663|\n",
      "|     5|  7.569693009969633|\n",
      "|     6| 13.063844288787255|\n",
      "|     7| 22.431131823598488|\n",
      "|     8|  24.10966813472571|\n",
      "|     9| 14.120499501843938|\n",
      "|    10| 11.759413413096187|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def activity_1_4(df_ratings):\n",
    "    \"\"\" Added column count which represents the number of voters\n",
    "        by notes.\n",
    "        Added a percentage column,\n",
    "        which is a transformation of the count column into a percentage.\n",
    "        Selection of rating and percentage columns.\n",
    "        Sort by rating column.\n",
    "\n",
    "    Args:\n",
    "        df_ratings (Dataframe): Rating Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_ratings.groupBy(\"rating\")\\\n",
    "        .count()\\\n",
    "        .withColumn(\n",
    "            'percentage',\n",
    "            (col(\"count\")*100)/float(df_ratings.count()))\\\n",
    "        .select(\"rating\", \"percentage\")\\\n",
    "        .orderBy(\"rating\")\\\n",
    "        .show()\n",
    "\n",
    "\n",
    "print(\"Ratings frequencies\")\n",
    "activity_1_4(df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data selection and enrichment\n",
    "\n",
    "- 2.1 In order to set up a certain statistical model, we must transform the `rating` note into two modalities: did the user like the film or not?\n",
    "     Create a new `liked` column in the `ratings` table with the following values: `0` for ratings [0-6] and `1` for ratings [7-10]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated ratings Dataframe\n",
      "+-------+--------+------+----------------+-----+\n",
      "|user_id|movie_id|rating|rating_timestamp|liked|\n",
      "+-------+--------+------+----------------+-----+\n",
      "|      1|  114508|     8|      1381006850|    1|\n",
      "|      2|  499549|     9|      1376753198|    1|\n",
      "|      2| 1305591|     8|      1376742507|    1|\n",
      "|      2| 1428538|     1|      1371307089|    0|\n",
      "|      3|   75314|     1|      1595468524|    0|\n",
      "|      3|  102926|     9|      1590148016|    1|\n",
      "|      3|  114369|    10|      1597555347|    1|\n",
      "|      3|  118715|     8|      1596006798|    1|\n",
      "|      3|  120737|     8|      1599306720|    1|\n",
      "|      3|  208092|     5|      1586466072|    0|\n",
      "|      3|  358273|     9|      1579057827|    1|\n",
      "|      3|  477348|     6|      1597289003|    0|\n",
      "|      3|10039344|     5|      1578603053|    0|\n",
      "|      3| 1051906|     6|      1589924916|    0|\n",
      "|      3| 1568346|     6|      1597388722|    0|\n",
      "|      3| 2278388|     8|      1597297732|    1|\n",
      "|      3| 6199572|     3|      1589482483|    0|\n",
      "|      3| 6723592|     8|      1599578941|    1|\n",
      "|      3| 6751668|     9|      1578955697|    1|\n",
      "|      3| 7131622|     8|      1579559244|    1|\n",
      "+-------+--------+------+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def activity_2_1(df_ratings):\n",
    "    \"\"\" Added a liked column.\n",
    "        Depending on the rating column,\n",
    "        the liked column takes the value 0 or 1\n",
    "\n",
    "    Args:\n",
    "        df_ratings (Dataframe): Ratings Dataframe\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Updated ratings Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_ratings = df_ratings\\\n",
    "        .withColumn(\n",
    "            'liked',\n",
    "            when(df_ratings.rating < 7, 0)\n",
    "            .when(df_ratings.rating >= 7, 1))\n",
    "\n",
    "    df_ratings.show()\n",
    "\n",
    "    return df_ratings\n",
    "\n",
    "\n",
    "print(\"Updated ratings Dataframe\")\n",
    "df_ratings = activity_2_1(df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.2 Which genres are rated highest by users? We want to get the **top 10** movie genres liked by users (using the new `liked` column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 genres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|    genre|sum_liked|\n",
      "+---------+---------+\n",
      "|    Drama|   397116|\n",
      "| Thriller|   220867|\n",
      "|   Action|   199212|\n",
      "|   Comedy|   169233|\n",
      "|Adventure|   169194|\n",
      "|    Crime|   136140|\n",
      "|   Sci-Fi|   131233|\n",
      "|  Romance|    92047|\n",
      "|  Mystery|    83036|\n",
      "|  Fantasy|    80337|\n",
      "+---------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def activity_2_2(df_movies, df_ratings):\n",
    "    \"\"\" Separation of genres in an array with the split function.\n",
    "        Extract genre arrays with the explode function alias explode_genre.\n",
    "        Selection of the movie_id and explode_genre column.\n",
    "        Joining with ratings table on movie_id columns.\n",
    "        Sum of the liked column by grouping on the explode_genre column.\n",
    "        Rename sum(liked) column to sum_liked.\n",
    "        Rename explode_genre column to genre.\n",
    "        Sort in descending order based on the sum_liked column.\n",
    "        Limitation to the first 10 records.\n",
    "\n",
    "    Args:\n",
    "        df_movies (Dataframe): Movies Dataframe\n",
    "        df_ratings (Dataframe): Ratings Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_movies.select(\n",
    "        \"movie_id\",\n",
    "        explode(\n",
    "            split(\n",
    "                col(\"genre\"),\n",
    "                \"\\|\"))\n",
    "        .alias(\"explode_genre\"))\\\n",
    "        .join(\n",
    "            df_ratings,\n",
    "            df_ratings.movie_id == df_movies.movie_id,\n",
    "            \"inner\")\\\n",
    "        .groupBy(\"explode_genre\")\\\n",
    "        .sum(\"liked\")\\\n",
    "        .withColumnRenamed(\"sum(liked)\", \"sum_liked\")\\\n",
    "        .withColumnRenamed(\"explode_genre\", \"genre\")\\\n",
    "        .sort(desc(\"sum_liked\"))\\\n",
    "        .limit(10)\\\n",
    "        .show()\n",
    "\n",
    "\n",
    "print(\"Top 10 genres\")\n",
    "activity_2_2(df_movies, df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Advanced Selections\n",
    "\n",
    "- 3.1 What are the titles of the films most popular with Internet users?\n",
    "     We are looking for the **10** films with the best ratings on average by users, with a minimum of **5** ratings for the measurement to be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|mean_rating|\n",
      "+--------------------+-----------+\n",
      "| Five Minutes (2017)|       10.0|\n",
      "|Crawl Bitch Crawl...|       10.0|\n",
      "|        Selam (2013)|       10.0|\n",
      "| Romeo Juliet (2009)|       10.0|\n",
      "|Third Contact (2011)|       10.0|\n",
      "|Let There Be Ligh...|       10.0|\n",
      "|Chasing Happiness...|       10.0|\n",
      "|Avengers: Age of ...|       10.0|\n",
      "|Make Like a Dog (...|       10.0|\n",
      "|Quiet Riot: Well ...|       10.0|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def activity_3_1(df_movies, df_ratings):\n",
    "    \"\"\" Join between movies and ratings tables,\n",
    "        on movie_id columns, alias movies_ratings.\n",
    "        Join with subtable alias title_count,\n",
    "        which represents the number of votes per film.\n",
    "        Filter on movies that have at least 5 ratings.\n",
    "        Average ratings per movie title.\n",
    "        Renamed avg(rating) column to mean_rating.\n",
    "        Descending sort based on mean_rating column.\n",
    "        Limitation to the first 10 records.\n",
    "\n",
    "    Args:\n",
    "        df_movies (Dataframe): Movies Dataframe\n",
    "        df_ratings (Dataframe): Ratings Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_movies.join(\n",
    "        df_ratings,\n",
    "        df_movies.movie_id == df_ratings.movie_id,\n",
    "        \"inner\").alias(\"movies_ratings\")\\\n",
    "        .join(\n",
    "            (df_movies.join(\n",
    "                df_ratings,\n",
    "                df_movies.movie_id == df_ratings.movie_id,\n",
    "                \"inner\")\n",
    "                .groupBy(\"title\")\n",
    "                .count()).alias(\"title_count\"),\n",
    "            col(\"movies_ratings.title\") == col(\"title_count.title\"),\n",
    "            \"inner\")\\\n",
    "        .filter(col(\"count\") >= 5)\\\n",
    "        .groupBy(\"movies_ratings.title\")\\\n",
    "        .mean(\"rating\")\\\n",
    "        .withColumnRenamed(\"avg(rating)\", \"mean_rating\")\\\n",
    "        .sort(desc(\"mean_rating\"))\\\n",
    "        .limit(10)\\\n",
    "        .show()\n",
    "\n",
    "\n",
    "print(\"Top 10 movies\")\n",
    "activity_3_1(df_movies, df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3.2 What is the most rated film in 2020?\n",
    "     **Note**: the `rating_timestamp` column is provided in the database as [Unix time](https://fr.wikipedia.org/wiki/Heure_Unix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best film of the year 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|      title|rating_count|\n",
      "+-----------+------------+\n",
      "|1917 (2019)|        2858|\n",
      "+-----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def activity_3_2(df_movies, df_ratings):\n",
    "    \"\"\" Adding a rating_year column,\n",
    "        which corresponds to the year in which the vote was recorded.\n",
    "        Join movies and ratings tables on movie_id columns.\n",
    "        Counting the number of votes per film title.\n",
    "        Sort descending in order of count.\n",
    "        Rename column count to rating_count.\n",
    "        Limitation to the first record.\n",
    "\n",
    "    Args:\n",
    "        df_movies (Dataframe): Movies Dataframe\n",
    "        df_ratings (Dataframe): Ratings Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_ratings\\\n",
    "        .withColumn(\n",
    "            'rating_year',\n",
    "            year(\n",
    "                from_unixtime('rating_timestamp')\n",
    "                .cast(DateType())))\\\n",
    "        .join(\n",
    "            df_movies,\n",
    "            df_ratings.movie_id == df_movies.movie_id)\\\n",
    "        .filter(col(\"rating_year\") == 2020)\\\n",
    "        .groupBy(\"title\")\\\n",
    "        .count()\\\n",
    "        .sort(desc(\"count\"))\\\n",
    "        .withColumnRenamed(\"count\", \"rating_count\")\\\n",
    "        .limit(1)\\\n",
    "        .show()\n",
    "\n",
    "\n",
    "print(\"Best film of the year 2020\")\n",
    "activity_3_2(df_movies, df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data management\n",
    "\n",
    "- 4.1 In order to find the notes of a particular user more quickly, we want to set up an index on the user ids.\n",
    "     Do you see a performance difference when looking up the ratings given by user `255`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Spark DataFrames are inherently unordered and do not support random access. (There is no built-in index concept like there is in pandas). Each row is treated as an independent collection of structured data, and this is what enables distributed parallel processing. So any executor can take any block of data and process it regardless of row order. [More info here](https://stackoverflow.com/questions/52792762/is-there-a-way-to-slice-dataframe-based-on-index-in-pyspark)\n",
    "\n",
    "Instead we can order the pyspark ratings dataframe according to the 'user_id' column. Otherwise the koalas package can be an alternative. Because Koala supports indexes and can be used for big data. Also, pandas cannot be scaled for big data oriented use.\n",
    "\n",
    "To check performance, I created the function time_test which print the execution time of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_test(func):\n",
    "    \"\"\" Check function time performance.\n",
    "\n",
    "    Args:\n",
    "        func (function): A function name\n",
    "    \"\"\"\n",
    "    time_list = []\n",
    "\n",
    "    for i in range(100):\n",
    "        start_time = time.time()\n",
    "        # beginning of the code to test\n",
    "        func()\n",
    "        # end of the code to test\n",
    "        time_list.append(time.time() - start_time)\n",
    "\n",
    "    mean_time = sum(time_list) / len(time_list)\n",
    "    max_time = max(time_list)\n",
    "    min_time = min(time_list)\n",
    "\n",
    "    print(\"min:\", min_time, \"mean:\", mean_time, \"max:\", max_time, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Dataframe to Pandas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for unindexed PYSPARK dataframe\n",
      "min: 0.004551887512207031 mean: 0.013537328243255615 max: 0.062064170837402344\n",
      "\n",
      "Execution time for PYSPARK dataframe indexed by 'user_id'\n",
      "min: 0.003513336181640625 mean: 0.009300875663757324 max: 0.030205965042114258\n",
      "\n",
      "Execution time for unindexed PANDAS dataframe\n",
      "min: 0.0008656978607177734 mean: 0.0017917799949645997 max: 0.02407217025756836\n",
      "\n",
      "Execution time for PANDAS dataframe indexed by 'user_id'\n",
      "min: 5.7220458984375e-05 mean: 0.0004215097427368164 max: 0.033597469329833984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def activity_4_1(df_ratings):\n",
    "    \"\"\"Compare time perfomance for indexed and not indexed Dataframe\n",
    "\n",
    "    Args:\n",
    "        df_ratings (Dataframe): Ratings Dataframe\n",
    "    \"\"\"\n",
    "    df_ratings_indexed = df_ratings.orderBy(\"user_id\")\n",
    "\n",
    "    print(\"Converting Dataframe to Pandas...\")\n",
    "    pandas_df_ratings = df_ratings.toPandas()\n",
    "    pandas_df_ratings_indexed = pandas_df_ratings.set_index(\"user_id\")\n",
    "\n",
    "    print(\"Execution time for unindexed PYSPARK dataframe\")\n",
    "    time_test(lambda: df_ratings.filter(col(\"user_id\") == 255))\n",
    "\n",
    "    print(\"Execution time for PYSPARK dataframe indexed by 'user_id'\")\n",
    "    time_test(lambda: df_ratings_indexed.filter(col(\"user_id\") == 255))\n",
    "\n",
    "    print(\"Execution time for unindexed PANDAS dataframe\")\n",
    "    time_test(\n",
    "        lambda: pandas_df_ratings\n",
    "        .loc[pandas_df_ratings.loc[:, \"user_id\"] == 255])\n",
    "\n",
    "    print(\"Execution time for PANDAS dataframe indexed by 'user_id'\")\n",
    "    time_test(lambda: pandas_df_ratings_indexed.loc[255])\n",
    "\n",
    "\n",
    "activity_4_1(df_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking:\n",
    "1. Indexed Pandas Dataframe\n",
    "2. Unindexed Pandas Dataframe\n",
    "3. Indexed Pyspark Dataframe / Unindexed Pyspark Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.ipynb#In[10]:22:18: W605 invalid escape sequence '\\|'\n",
      "result.ipynb#In[ ]:1:80: E501 line too long (92 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "!flake8-nb result.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safe notebook versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook result.ipynb to python\n",
      "[NbConvertApp] Writing 12924 bytes to result.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert result.ipynb --to=\"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook result.ipynb to webpdf\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 152158 bytes to result.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to webpdf --allow-chromium-download result.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('test_heva')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64a6df10e2c5214e0607b70b4fb1785e65c456952a5c675fa786aef034d7f982"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
